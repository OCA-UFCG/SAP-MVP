max(ambas_apis$distancia_entre_apis_m, na.rm = TRUE)))
cat("\n   N√≠vel de concord√¢ncia:\n")
tabela_concordancia <- table(ambas_apis$concordancia)
for(nivel in names(tabela_concordancia)) {
cat(sprintf("   %-10s: %3d (%.1f%%)\n",
nivel,
tabela_concordancia[nivel],
(tabela_concordancia[nivel]/nrow(ambas_apis))*100))
}
}
# ==============================================================================
# 7. EXPORTAR RESULTADOS
# ==============================================================================
cat("\n====================================================================\n")
cat("  EXPORTANDO ARQUIVOS\n")
cat("====================================================================\n\n")
# 1. Arquivo completo
write_xlsx(dados_consolidados, "geocodificacao_completa_osm_arcgis.xlsx")
cat("‚úì geocodificacao_completa_osm_arcgis.xlsx\n")
# 2. Arquivo simplificado - apenas resultado final
dados_simplificado <- dados_consolidados %>%
select(
`Endere√ßo completo`,
x = x_final,
y = y_final,
fonte = fonte_final,
status = status_combinado
)
write_xlsx(dados_simplificado, "enderecos_geocodificados_final.xlsx")
cat("‚úì enderecos_geocodificados_final.xlsx ‚≠ê (USE ESTE!)\n")
# 3. Apenas endere√ßos v√°lidos
dados_validos <- dados_simplificado %>%
filter(!is.na(x) & !is.na(y))
write_xlsx(dados_validos, "enderecos_validos_final.xlsx")
cat(sprintf("‚úì enderecos_validos_final.xlsx (%d endere√ßos)\n", nrow(dados_validos)))
# 4. CSV para GIS
write.csv(dados_validos, "coordenadas_finais_para_gis.csv",
row.names = FALSE, fileEncoding = "UTF-8")
cat("‚úì coordenadas_finais_para_gis.csv\n")
# 5. Endere√ßos n√£o geocodificados
dados_falha <- dados_consolidados %>%
filter(is.na(x_final))
if(nrow(dados_falha) > 0) {
write_xlsx(dados_falha %>%
select(`Endere√ßo completo`, status_osm, status_arcgis),
"enderecos_nao_geocodificados.xlsx")
cat(sprintf("‚úì enderecos_nao_geocodificados.xlsx (%d endere√ßos)\n", nrow(dados_falha)))
}
# 6. Relat√≥rio de compara√ß√£o detalhado
if(nrow(ambas_apis) > 0) {
relatorio_comparacao <- ambas_apis %>%
select(
`Endere√ßo completo`,
x_osm, y_osm,
x_arcgis, y_arcgis,
distancia_entre_apis_m,
concordancia,
x_final, y_final,
fonte_final
) %>%
arrange(desc(distancia_entre_apis_m))
write_xlsx(relatorio_comparacao, "relatorio_comparacao_apis.xlsx")
cat("‚úì relatorio_comparacao_apis.xlsx\n")
}
# 7. Casos divergentes
casos_divergentes <- ambas_apis %>%
filter(concordancia == "Baixa") %>%
select(
`Endere√ßo completo`,
x_osm, y_osm,
x_arcgis, y_arcgis,
distancia_entre_apis_m
) %>%
arrange(desc(distancia_entre_apis_m))
if(nrow(casos_divergentes) > 0) {
write_xlsx(casos_divergentes, "casos_divergentes_investigar.xlsx")
cat(sprintf("‚ö†Ô∏è  casos_divergentes_investigar.xlsx (%d casos)\n",
nrow(casos_divergentes)))
}
# ==============================================================================
# 8. RESUMO FINAL
# ==============================================================================
cat("\n====================================================================\n")
cat("  ‚úÖ PROCESSO CONCLU√çDO COM SUCESSO!\n")
cat("====================================================================\n\n")
cat("üìÅ Arquivos principais:\n")
cat("   1. enderecos_geocodificados_final.xlsx ‚≠ê (USE ESTE!)\n")
cat("   2. enderecos_validos_final.xlsx (apenas v√°lidos)\n")
cat("   3. coordenadas_finais_para_gis.csv (para SIG)\n\n")
cat("üìä Resumo dos resultados:\n")
cat(sprintf("   Total: %d endere√ßos\n", total_enderecos))
cat(sprintf("   ‚úÖ Geocodificados: %d (%.1f%%)\n",
total_final, (total_final/total_enderecos)*100))
cat(sprintf("   ‚ùå N√£o geocodificados: %d (%.1f%%)\n",
total_enderecos - total_final,
((total_enderecos - total_final)/total_enderecos)*100))
cat("\n")
shiny::runApp()
runApp()
runApp()
View(base)
runApp()
R.version.string
build_unified_sf <- function(df1, df2, df3, mun_sf_raw) {
pkgs <- c("dplyr","readr","stringr","stringi","janitor","sf","tibble","purrr")
to_install <- pkgs[!pkgs %in% rownames(installed.packages())]
if (length(to_install)) install.packages(to_install, quiet = TRUE)
lapply(pkgs, require, character.only = TRUE)
# helpers ---------------------------------------------------------------
to_ibge <- function(x) {
if (is.numeric(x)) x <- as.character(as.integer(x))
x <- gsub("\\D", "", x)
stringr::str_pad(x, width = 7, pad = "0")
}
clean_pt_names <- function(nms) {
nms %>% stringi::stri_trans_general("Latin-ASCII") %>% janitor::make_clean_names()
}
# (NOTA: A fun√ß√£o guess_locale foi mantida, mas n√£o √© mais usada pelo IFDM)
guess_locale <- function(x) {
if (any(grepl(",", x, fixed = TRUE), na.rm = TRUE))
readr::locale(decimal_mark = ",", grouping_mark = ".")
else
readr::locale(decimal_mark = ".", grouping_mark = ",")
}
# --- 1) Normalizar chaves ---------------------------------------------
df1 <- df1 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df2 <- df2 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df3 <- df3 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
mun_sf <- mun_sf_raw %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
# --- 2) Sele√ß√µes de colunas -------------------------------------------
# df1: IFDM (char->num), SPE_mean, IA_mean, ID_Crit
stopifnot(all(c("CD_MUN","IFDM","SPE_mean","IA_mean","ID_Crit") %in% names(df1)))
# (REMOVIDO) A linha 'loc_ifdm <- guess_locale(df1$IFDM)' foi removida.
df1_sel <- df1 %>%
transmute(
CD_MUN,
# (CORRIGIDO) For√ßa o locale a usar "." como decimal.
# O parse_number() do readr √© inteligente o suficiente
# para ignorar separadores de milhar (como v√≠rgulas)
# se eles n√£o forem o decimal_mark.
IFDM = readr::parse_number(IFDM, locale = readr::locale(decimal_mark = ".")),
SPE_mean = as.numeric(SPE_mean),
IA_mean  = as.numeric(IA_mean),
ID_Crit  = as.numeric(ID_Crit)
)
# df2: da coluna "Popula√ß√£o 2022" at√© "Nota Mediana do Enem"
nms2 <- names(df2)
i_start <- match("Popula√ß√£o 2022", nms2)
i_end   <- match("Nota Mediana do Enem", nms2)
if (is.na(i_start) || is.na(i_end) || i_start > i_end) {
stop("N√£o encontrei o range 'Popula√ß√£o 2022' .. 'Nota Mediana do Enem' em df2.")
}
cols_range <- nms2[i_start:i_end]
df2_slice <- df2 %>% dplyr::select(CD_MUN, dplyr::all_of(cols_range))
# df3: rural_pop_perc
stopifnot(all(c("CD_MUN", "rural_pop_perc") %in% names(df3)))
df3_sel <- df3 %>%
transmute(
CD_MUN,
rural_pop_perc = as.numeric(rural_pop_perc)
)
# --- 3) Limpar nomes e criar dicion√°rio -------------------------------
dict_df2 <- tibble(
original = names(df2_slice),
limpo    = c("CD_MUN", clean_pt_names(names(df2_slice)[-1]))
)
names(df2_slice) <- dict_df2$limpo
# Tamb√©m padronizar nomes de df1_sel
dict_df1 <- tibble(
original = names(df1_sel),
limpo    = clean_pt_names(names(df1_sel))
)
names(df1_sel) <- dict_df1$limpo  # vira: cd_mun, ifdm, spe_mean, ia_mean, id_crit
# Tamb√©m padronizar nomes de df3_sel
dict_df3 <- tibble(
original = names(df3_sel),
limpo    = clean_pt_names(names(df3_sel))
)
names(df3_sel) <- dict_df3$limpo # vira: cd_mun, rural_pop_perc
# --- 4) Checagens antes do join ---------------------------------------
dup_df1 <- df1_sel %>% count(cd_mun) %>% filter(n > 1)
dup_df2 <- df2_slice %>% count(CD_MUN) %>% filter(n > 1)
dup_df3 <- df3_sel %>% count(cd_mun) %>% filter(n > 1)
if (nrow(dup_df1) > 0) message("Aten√ß√£o: df1 tem chaves duplicadas. Revise antes do join.")
if (nrow(dup_df2) > 0) message("Aten√ß√£o: df2 tem chaves duplicadas no recorte. Revise antes do join.")
if (nrow(dup_df3) > 0) message("Aten√ß√£o: df3 tem chaves duplicadas. Revise antes do join.")
# --- 5) Join no vetor (atributivo, por c√≥digo) ------------------------
base_sf <- mun_sf %>%
left_join(df1_sel, by = c("CD_MUN" = "cd_mun")) %>%
left_join(df2_slice, by = "CD_MUN") %>%
left_join(df3_sel, by = c("CD_MUN" = "cd_mun"))
# --- 6) P√≥s-join: checagens e resumo ----------------------------------
miss_d1 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(ifdm)) %>% nrow()
miss_d2 <- base_sf %>% st_drop_geometry() %>%
filter(rowSums(is.na(across(all_of(dict_df2$limpo[-1])))) == length(dict_df2$limpo[-1])) %>% nrow()
miss_d3 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(!!sym(dict_df3$limpo[2]))) %>% nrow()
checks <- list(
n_sf = nrow(mun_sf),
dup_df1 = dup_df1,
dup_df2 = dup_df2,
dup_df3 = dup_df3,
n_sem_ifdm_pos_join = miss_d1,
n_sem_bloco_df2_pos_join = miss_d2,
n_sem_rural_pop_perc_pos_join = miss_d3,
crs = sf::st_crs(mun_sf)
)
# --- 7) Retorno --------------------------------------------------------
list(
base_sf = base_sf,
dict = list(df1 = dict_df1, df2 = dict_df2, df3 = dict_df3),
checks = checks
)
}
path <- "C:/Users/artur/OneDrive - academico.ifpb.edu.br/Takeout Academico/Drive/Phd/UFCG/MMA - Municipios SAB/R_project"
xlsx_path  <- paste(path,'/',"dados2.xlsx")
xlsx_path
xlsx_path  <- paste0(path,'/',"dados2.xlsx")
xlsx_path
path <- "C:/Users/artur/OneDrive - academico.ifpb.edu.br/Takeout Academico/Drive/Phd/UFCG/MMA - Municipios SAB/R_project"
xlsx_path  <- paste0(path,'/',"dados2.xlsx")
xlsx_path2 <- paste0(path,'/',"ips_brasil_municipios_2025.xlsx")
xlsx_path3 <- paste0(path,'/',"pobreza_rural_10_2025.xlsx")
# 1) L√™ o primeiro arquivo (tem CD_MUN)
df1 <- read_excel(xlsx_path)
library(readxl)
# 1) L√™ o primeiro arquivo (tem CD_MUN)
df1 <- read_excel(xlsx_path)
# 2) L√™ o segundo arquivo (tem 'C√≥digo IBGE' e 'IPS')
df2_raw <- read_excel(xlsx_path2)
df3_raw <- read_excel(xlsx_path3)
mun_path   <- "pab_mun.gpkg"
mun_sf_raw <- sf::st_read(mun_path)
mun_path   <- paste0(path,'/',"pab_mun.gpkg")
mun_sf_raw <- sf::st_read(mun_path)
# Uso:
out <- build_unified_sf(df1, df2_raw, df3_raw, mun_sf_raw)
build_unified_sf <- function(df1, df2, df3, mun_sf_raw) {
pkgs <- c("dplyr","readr","stringr","stringi","janitor","sf","tibble","purrr")
to_install <- pkgs[!pkgs %in% rownames(installed.packages())]
if (length(to_install)) install.packages(to_install, quiet = TRUE)
lapply(pkgs, require, character.only = TRUE)
# helpers ---------------------------------------------------------------
to_ibge <- function(x) {
if (is.numeric(x)) x <- as.character(as.integer(x))
x <- gsub("\\D", "", x)
stringr::str_pad(x, width = 7, pad = "0")
}
clean_pt_names <- function(nms) {
nms %>% stringi::stri_trans_general("Latin-ASCII") %>% janitor::make_clean_names()
}
# (NOTA: A fun√ß√£o guess_locale foi mantida, mas n√£o √© mais usada pelo IFDM)
guess_locale <- function(x) {
if (any(grepl(",", x, fixed = TRUE), na.rm = TRUE))
readr::locale(decimal_mark = ",", grouping_mark = ".")
else
readr::locale(decimal_mark = ".", grouping_mark = ",")
}
# --- 1) Normalizar chaves ---------------------------------------------
df1 <- df1 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df2 <- df2 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df3 <- df3 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
mun_sf <- mun_sf_raw %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
# --- 2) Sele√ß√µes de colunas -------------------------------------------
# df1: IFDM (char->num), SPE_mean, IA_mean, ID_Crit
stopifnot(all(c("CD_MUN","IFDM","SPE_mean","IA_mean","ID_Crit") %in% names(df1)))
# (REMOVIDO) A linha 'loc_ifdm <- guess_locale(df1$IFDM)' foi removida.
df1_sel <- df1 %>%
transmute(
CD_MUN,
# (CORRIGIDO) For√ßa o locale a usar "." como decimal.
# O parse_number() do readr √© inteligente o suficiente
# para ignorar separadores de milhar (como v√≠rgulas)
# se eles n√£o forem o decimal_mark.
IFDM = readr::parse_number(IFDM, locale = readr::locale(decimal_mark = ".")),
SPE_mean = as.numeric(SPE_mean),
IA_mean  = as.numeric(IA_mean),
ID_Crit  = as.numeric(ID_Crit)
)
# df2: da coluna "Popula√ß√£o 2022" at√© "Nota Mediana do Enem"
nms2 <- names(df2)
i_start <- match("Popula√ß√£o 2022", nms2)
i_end   <- match("Nota Mediana do Enem", nms2)
if (is.na(i_start) || is.na(i_end) || i_start > i_end) {
stop("N√£o encontrei o range 'Popula√ß√£o 2022' .. 'Nota Mediana do Enem' em df2.")
}
cols_range <- nms2[i_start:i_end]
df2_slice <- df2 %>% dplyr::select(CD_MUN, dplyr::all_of(cols_range))
# df3: rural_poverty
stopifnot(all(c("CD_MUN", "rural_poverty") %in% names(df3)))
df3_sel <- df3 %>%
transmute(
CD_MUN,
rural_poverty = as.numeric(rural_poverty)
)
# --- 3) Limpar nomes e criar dicion√°rio -------------------------------
dict_df2 <- tibble(
original = names(df2_slice),
limpo    = c("CD_MUN", clean_pt_names(names(df2_slice)[-1]))
)
names(df2_slice) <- dict_df2$limpo
# Tamb√©m padronizar nomes de df1_sel
dict_df1 <- tibble(
original = names(df1_sel),
limpo    = clean_pt_names(names(df1_sel))
)
names(df1_sel) <- dict_df1$limpo  # vira: cd_mun, ifdm, spe_mean, ia_mean, id_crit
# Tamb√©m padronizar nomes de df3_sel
dict_df3 <- tibble(
original = names(df3_sel),
limpo    = clean_pt_names(names(df3_sel))
)
names(df3_sel) <- dict_df3$limpo # vira: cd_mun, rural_pop_perc
# --- 4) Checagens antes do join ---------------------------------------
dup_df1 <- df1_sel %>% count(cd_mun) %>% filter(n > 1)
dup_df2 <- df2_slice %>% count(CD_MUN) %>% filter(n > 1)
dup_df3 <- df3_sel %>% count(cd_mun) %>% filter(n > 1)
if (nrow(dup_df1) > 0) message("Aten√ß√£o: df1 tem chaves duplicadas. Revise antes do join.")
if (nrow(dup_df2) > 0) message("Aten√ß√£o: df2 tem chaves duplicadas no recorte. Revise antes do join.")
if (nrow(dup_df3) > 0) message("Aten√ß√£o: df3 tem chaves duplicadas. Revise antes do join.")
# --- 5) Join no vetor (atributivo, por c√≥digo) ------------------------
base_sf <- mun_sf %>%
left_join(df1_sel, by = c("CD_MUN" = "cd_mun")) %>%
left_join(df2_slice, by = "CD_MUN") %>%
left_join(df3_sel, by = c("CD_MUN" = "cd_mun"))
# --- 6) P√≥s-join: checagens e resumo ----------------------------------
miss_d1 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(ifdm)) %>% nrow()
miss_d2 <- base_sf %>% st_drop_geometry() %>%
filter(rowSums(is.na(across(all_of(dict_df2$limpo[-1])))) == length(dict_df2$limpo[-1])) %>% nrow()
miss_d3 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(!!sym(dict_df3$limpo[2]))) %>% nrow()
checks <- list(
n_sf = nrow(mun_sf),
dup_df1 = dup_df1,
dup_df2 = dup_df2,
dup_df3 = dup_df3,
n_sem_ifdm_pos_join = miss_d1,
n_sem_bloco_df2_pos_join = miss_d2,
n_sem_rural_pop_perc_pos_join = miss_d3,
crs = sf::st_crs(mun_sf)
)
# --- 7) Retorno --------------------------------------------------------
list(
base_sf = base_sf,
dict = list(df1 = dict_df1, df2 = dict_df2, df3 = dict_df3),
checks = checks
)
}
# Uso:
out <- build_unified_sf(df1, df2_raw, df3_raw, mun_sf_raw)
base <- out$base_sf |>
sf::st_make_valid() %>%
sf::st_transform(4326)
qs::qsave(base, "app_master_sf.qs", preset = "fast")
runApp()
View(base)
runApp()
qs::qsave(base, "app_master_sf.qs", preset = "fast")
runApp()
build_unified_sf <- function(df1, df2, df3, mun_sf_raw) {
pkgs <- c("dplyr","readr","stringr","stringi","janitor","sf","tibble","purrr")
to_install <- pkgs[!pkgs %in% rownames(installed.packages())]
if (length(to_install)) install.packages(to_install, quiet = TRUE)
lapply(pkgs, require, character.only = TRUE)
# helpers ---------------------------------------------------------------
to_ibge <- function(x) {
if (is.numeric(x)) x <- as.character(as.integer(x))
x <- gsub("\\D", "", x)
stringr::str_pad(x, width = 7, pad = "0")
}
clean_pt_names <- function(nms) {
nms %>% stringi::stri_trans_general("Latin-ASCII") %>% janitor::make_clean_names()
}
# (NOTA: A fun√ß√£o guess_locale foi mantida, mas n√£o √© mais usada pelo IFDM)
guess_locale <- function(x) {
if (any(grepl(",", x, fixed = TRUE), na.rm = TRUE))
readr::locale(decimal_mark = ",", grouping_mark = ".")
else
readr::locale(decimal_mark = ".", grouping_mark = ",")
}
# --- 1) Normalizar chaves ---------------------------------------------
df1 <- df1 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df2 <- df2 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
df3 <- df3 %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
mun_sf <- mun_sf_raw %>% mutate(CD_MUN = to_ibge(.data$CD_MUN))
# --- 2) Sele√ß√µes de colunas -------------------------------------------
# df1: IFDM (char->num), SPE_mean, IA_mean, ID_Crit
stopifnot(all(c("CD_MUN","IFDM","SPE_mean","IA_mean","ID_Crit") %in% names(df1)))
# (REMOVIDO) A linha 'loc_ifdm <- guess_locale(df1$IFDM)' foi removida.
df1_sel <- df1 %>%
transmute(
CD_MUN,
# (CORRIGIDO) For√ßa o locale a usar "." como decimal.
# O parse_number() do readr √© inteligente o suficiente
# para ignorar separadores de milhar (como v√≠rgulas)
# se eles n√£o forem o decimal_mark.
IFDM = readr::parse_number(IFDM, locale = readr::locale(decimal_mark = ".")),
SPE_mean = as.numeric(SPE_mean),
IA_mean  = as.numeric(IA_mean),
ID_Crit  = as.numeric(ID_Crit)
)
# df2: da coluna "Popula√ß√£o 2022" at√© "Nota Mediana do Enem"
nms2 <- names(df2)
i_start <- match("Popula√ß√£o 2022", nms2)
i_end   <- match("Nota Mediana do Enem", nms2)
if (is.na(i_start) || is.na(i_end) || i_start > i_end) {
stop("N√£o encontrei o range 'Popula√ß√£o 2022' .. 'Nota Mediana do Enem' em df2.")
}
cols_range <- nms2[i_start:i_end]
df2_slice <- df2 %>% dplyr::select(CD_MUN, dplyr::all_of(cols_range))
# df3: rural_poverty
stopifnot(all(c("CD_MUN", "rural_poverty") %in% names(df3)))
df3_sel <- df3 %>%
transmute(
CD_MUN,
rural_poverty = as.numeric(rural_poverty)
)
# --- 3) Limpar nomes e criar dicion√°rio -------------------------------
dict_df2 <- tibble(
original = names(df2_slice),
limpo    = c("CD_MUN", clean_pt_names(names(df2_slice)[-1]))
)
names(df2_slice) <- dict_df2$limpo
# Tamb√©m padronizar nomes de df1_sel
dict_df1 <- tibble(
original = names(df1_sel),
limpo    = clean_pt_names(names(df1_sel))
)
names(df1_sel) <- dict_df1$limpo  # vira: cd_mun, ifdm, spe_mean, ia_mean, id_crit
# Tamb√©m padronizar nomes de df3_sel
dict_df3 <- tibble(
original = names(df3_sel),
limpo    = clean_pt_names(names(df3_sel))
)
names(df3_sel) <- dict_df3$limpo # vira: cd_mun, rural_pop_perc
# --- 4) Checagens antes do join ---------------------------------------
dup_df1 <- df1_sel %>% count(cd_mun) %>% filter(n > 1)
dup_df2 <- df2_slice %>% count(CD_MUN) %>% filter(n > 1)
dup_df3 <- df3_sel %>% count(cd_mun) %>% filter(n > 1)
if (nrow(dup_df1) > 0) message("Aten√ß√£o: df1 tem chaves duplicadas. Revise antes do join.")
if (nrow(dup_df2) > 0) message("Aten√ß√£o: df2 tem chaves duplicadas no recorte. Revise antes do join.")
if (nrow(dup_df3) > 0) message("Aten√ß√£o: df3 tem chaves duplicadas. Revise antes do join.")
# --- 5) Join no vetor (atributivo, por c√≥digo) ------------------------
base_sf <- mun_sf %>%
left_join(df1_sel, by = c("CD_MUN" = "cd_mun")) %>%
left_join(df2_slice, by = "CD_MUN") %>%
left_join(df3_sel, by = c("CD_MUN" = "cd_mun"))
# --- 6) P√≥s-join: checagens e resumo ----------------------------------
miss_d1 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(ifdm)) %>% nrow()
miss_d2 <- base_sf %>% st_drop_geometry() %>%
filter(rowSums(is.na(across(all_of(dict_df2$limpo[-1])))) == length(dict_df2$limpo[-1])) %>% nrow()
miss_d3 <- base_sf %>% st_drop_geometry() %>%
filter(is.na(!!sym(dict_df3$limpo[2]))) %>% nrow()
checks <- list(
n_sf = nrow(mun_sf),
dup_df1 = dup_df1,
dup_df2 = dup_df2,
dup_df3 = dup_df3,
n_sem_ifdm_pos_join = miss_d1,
n_sem_bloco_df2_pos_join = miss_d2,
n_sem_rural_pop_perc_pos_join = miss_d3,
crs = sf::st_crs(mun_sf)
)
# --- 7) Retorno --------------------------------------------------------
list(
base_sf = base_sf,
dict = list(df1 = dict_df1, df2 = dict_df2, df3 = dict_df3),
checks = checks
)
}
path <- "C:/Users/artur/OneDrive - academico.ifpb.edu.br/Takeout Academico/Drive/Phd/UFCG/MMA - Municipios SAB/R_project"
xlsx_path  <- paste0(path,'/',"dados2.xlsx")
xlsx_path2 <- paste0(path,'/',"ips_brasil_municipios_2025.xlsx")
xlsx_path3 <- paste0(path,'/',"pobreza_rural_10_2025.xlsx")
# 1) L√™ o primeiro arquivo (tem CD_MUN)
df1 <- read_excel(xlsx_path)
# 2) L√™ o segundo arquivo (tem 'C√≥digo IBGE' e 'IPS')
df2_raw <- read_excel(xlsx_path2)
df3_raw <- read_excel(xlsx_path3)
mun_path   <- paste0(path,'/',"pab_mun.gpkg")
mun_sf_raw <- sf::st_read(mun_path)
# Uso:
out <- build_unified_sf(df1, df2_raw, df3_raw, mun_sf_raw)
base <- out$base_sf |>
sf::st_make_valid() %>%
sf::st_transform(4326)
# sf::st_simplify()
qs::qsave(base, "app_master_sf.qs", preset = "fast")
# qs::qsave(base, "app_master_sf_full.qs", preset = "balanced")
# out$checks
# sf::st_geometry_type(base)[1]; sf::st_crs(base)
# saveRDS(base, "data/processed/base_sf.rds")  # salve para usar no app
View(base)
base$rural_poverty
runApp()
View(base)
runApp()
runApp()
runApp()
runApp()
View(mod_preproc_server)
runApp()
runApp()
runApp()
runApp()
library(shinyjs)
runApp()
runApp()
runApp()
